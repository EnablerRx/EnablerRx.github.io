---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

# Contact
-------
**Email**: jieruan75[at]gmail[dot]com  
**Twitter**: @JieRuan75  
**Wechat**: 1151334747  

# About Me

Hi, my name is Jie Ruan. Currently, I am a second-year PhD student at University of Michigan. I am fortunate to have Prof. [Lu Wang](https://web.eecs.umich.edu/~wangluxy/) as my advisor and I am a member of [LAUNCH Lab](https://launch.eecs.umich.edu/). 


I received my master degree from Peking University, advised by Prof. [Yuesheng Zhu](https://scholar.google.com/citations?user=HBp_nuAAAAAJ&hl=zh-CN) and Prof. [Guibo Luo](https://scholar.google.com/citations?user=kUIPmL4AAAAJ&hl=zh-CN&oi=ao), and had the privilege of working closely with Prof. [Xiaojun Wan](https://scholar.google.com/citations?user=lTTeBdkAAAAJ&hl=zh-CN&oi=ao). 
<!-- Check out my [CV](https://github.com/EnablerRx/EnablerRx.github.io/blob/master/files/CV.pdf) for more details.-->

My research interest broadly lies in AI and its constructive impacts on humanity. I aspire to deliver Trustworthy AI, including areas such as reliable evaluation, alignment, and scalable oversight. And I am dedicated to unleashing the full potential of imperfect AI in practical applications, especially in fields like psychology, medicine, education, social good, and science.

<!-- I am currently working on LLM evaluation, with a focus on constructing benchmarks that reflect the complexity of real-world scenarios and creating reliable automatic evaluation methods.-->

Feel free to reach out to me if you'd like to discuss research or explore potential collaboration!  

I am seeking self-motivated undergraduate or master‚Äôs students to work on LLM evaluation. If you‚Äôre interested, I‚Äôd be happy to hear from you!

<!-- 

I am currently pursuing a master's degree at Peking University, focusing on natural language generation and evaluation. 

My research interest broadly lies in Artificial Intelligence (AI) and its constructive impacts on humanity. I aspire to deliver Trustworthy and Human-centered AI, including areas such as reliable evaluation, human-AI collaboration, and AI safety. And I am dedicated to unleashing the full potential of imperfect AI in practical applications, emphasizing effective collaboration between humans and AI, especially in fields like medicine, social good, and science.


If you are interested in collaboration, please reach out! I'm more than happy to chat about opportunities here!
-->
# Selected Publications/Preprints
ExpertLongBench: Benchmarking Language Models on Expert-Level Long-Form Generation Tasks with Structured Checklists [Paper](https://arxiv.org/abs/2506.01241) [Link](https://huggingface.co/spaces/launch/ExpertLongBench)  
**Jie Ruan‚Ä†**, Inderjeet Nair‚Ä†, Shuyang Cao‚Ä†, Amy Liu, Sheza Munir, Micah Pollens-Dempsey, Tiffany Chiang, Lucy Kates, Nicholas David, Sihan Chen, Ruxin Yang, Yuqian Yang, Jasmine Gump, Tessa Bialek, Vivek Sankaran, Margo Schlanger, Lu Wang

Defining and Detecting Vulnerability in Human Evaluation Guidelines: A Preliminary Study Towards Reliable NLG Evaluation [Paper](https://arxiv.org/pdf/2406.07935) [Code](https://github.com/EnablerRx/GuidelineVulnDetect)  
**Jie Ruan‚Ä†**, Wenqing Wang‚Ä†, Xiaojun Wan   
üèÜ NAACL 2024, Outstanding Paper Award  


Better than Random: Reliable NLG Human Evaluation with Constrained Active Sampling. [Paper](https://arxiv.org/pdf/2406.07967v1) [Code](https://github.com/EnablerRx/CASF)  
**Jie Ruan**, Xiao Pu, Mingqi Gao, Xiaojun Wan and Yuesheng Zhu   
AAAI 2024  


Benchmarking knowledge boundary for large language model: A different perspective on model evaluation. [Paper](https://arxiv.org/pdf/2402.11493) [Code](https://github.com/pkulcwmzx/knowledge_boundary)  
Xunjian Yin, Xu Zhang, **Jie Ruan**, Xiaojun Wan    
ACL 2024  


Describe Images in a *Boring* Way: Towards Cross-Modal Sarcasm Generation. [Paper](https://openaccess.thecvf.com/content/WACV2024/papers/Ruan_Describe_Images_in_a_Boring_Way_Towards_Cross-Modal_Sarcasm_Generation_WACV_2024_paper.pdf) [Code](https://github.com/EnablerRx/CMSG-EGRM)  
**Jie Ruan**, Yue Wu, Xiaojun Wan and Yuesheng Zhu   
WACV 2024  

Human-like Summarization Evaluation with ChatGPT. [Paper](https://arxiv.org/pdf/2304.02554)     
Mingqi Gao, **Jie Ruan**, Renliang Sun, Xunjian Yin, Shiping Yang, Xiaojun Wan    

ReproHum\# 0087-01: A Reproduction Study of the Human Evaluation of the Coverage of Fact Checking Explanations. [paper](https://aclanthology.org/2024.humeval-1.25.pdf)   
Mingqi Gao, **Jie Ruan**, Xiaojun Wan  
Proceedings of the Fourth Workshop on Human Evaluation of NLP Systems (HumEval) @ LREC-COLING 2024.

A Reproduction Study of the Human Evaluation of Role-Oriented Dialogue Summarization Models. [Paper](https://humeval.github.io/papers/1_Paper.pdf)   
Mingqi Gao, **Jie Ruan**, Xiaojun Wan   
HumEval at RANLP 2023. The 3rd Workshop on Human Evaluation of NLP Systems (HumEval‚Äô23)



# Selected Awards
NAACL 2024 Outstanding Paper Award (2024)  
Peking University Outstanding Graduate (2024)  
Peking University Outstanding Graduation Thesis (2024)  
Academic Excellence Award of Peking University (2023)  
Good Youth of Progressive and Kind in Guangdong Province (2022)  
Outstanding Undergraduate Thesis (2021)  
Outstanding Undergraduate Student (2021)  
National Scholarship (2021)  
Provincial Mathematical Modeling Competition - First Prize (2019)  
City Award for Excellence in Computer Science Research - First Prize (2019)  

# Academic Service
**Reviewer**: ARR, ICML, AAAI, ICMR, IEEE Computational Intelligence Magazine  
<!-- **Program Committee**: ICMR, AAAI -->


<!-- 

Talks
- **Towards Reliable NLG Evaluation**
University of Michigan, 2024

- **Reliable NLG Human Evaluation with Constrained Active Sampling**    
Saarland University, 2023    
Southern University of Science and Technologyy, 2023

-->

